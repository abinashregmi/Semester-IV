# -*- coding: utf-8 -*-
"""Lab14(SalaryDataUsingMultilayerPerceptron).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1W3z_y0p4znMUFI8uZ_sDq4i6QlvXTHb2
"""

import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
import matplotlib.pyplot as plt

df = pd.read_csv('/Salary Data.csv')
df.dropna(inplace=True)

X_np = df[['Years of Experience']].values.astype(np.float32)
y_np = df[['Salary']].values.astype(np.float32)

X_mean, X_std = X_np.mean(axis=0), X_np.std(axis=0)
y_mean, y_std = y_np.mean(axis=0), y_np.std(axis=0)

X_scaled = (X_np - X_mean) / X_std
y_scaled = (y_np - y_mean) / y_std

X = torch.from_numpy(X_scaled)
y = torch.from_numpy(y_scaled)

class MLP(nn.Module):
    def __init__(self):
        super(MLP, self).__init__()
        self.layers = nn.Sequential(
            nn.Linear(1, 16),
            nn.ReLU(),
            nn.Linear(16, 1)
        )

    def forward(self, x):
        return self.layers(x)

def train_model(model, X, y, learning_rate, num_epochs=1000):
    criterion = nn.MSELoss()
    optimizer = optim.Adam(model.parameters(), lr=learning_rate)

    losses = []

    for epoch in range(num_epochs):
        model.train()
        outputs = model(X)
        loss = criterion(outputs, y)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        losses.append(loss.item())

        if (epoch + 1) % 100 == 0:
            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.6f}')

    print(f'Training complete for LR: {learning_rate}')

    weights = [param.data.clone() for param in model.parameters()]

    return losses, weights

learning_rates = [0.1, 0.01, 0.001]
results = {}

for lr in learning_rates:
    print(f"\nTraining with Learning Rate: {lr} ")
    model = MLP()

    losses, weights = train_model(model, X, y, lr)

    results[lr] = {
        'losses': losses,
        'final_loss': losses[-1],
        'weights': weights
    }

plt.figure(figsize=(10, 6))
for lr, data in results.items():
    plt.plot(data['losses'], label=f'LR = {lr}')

plt.title('Loss Curves for Different Learning Rates')
plt.xlabel('Epochs')
plt.ylabel('Mean Squared Error (MSE)')
plt.legend()
plt.grid(True)
plt.savefig('loss_curves.png')
plt.show()